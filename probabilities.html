<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 8 Probabilities | Decision Theory" />
<meta property="og:type" content="book" />

<meta property="og:description" content="This is a draft of a decision theory book written in BookDown" />
<meta name="github-repo" content="bertybaums/decisiontheory" />

<meta name="author" content="Bert Baumgaertner" />

<meta name="date" content="2022-08-24" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="/usr/share/javascript/mathjax/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="This is a draft of a decision theory book written in BookDown">

<title>Chapter 8 Probabilities | Decision Theory</title>

<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-background.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />





<link rel="stylesheet" href="toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="has-sub"><a href="index.html#preface-and-prerequisites">Preface and Prerequisites</a><ul>
<li><a href="index.html#what-is-a-conceptual-introduction"><span class="toc-section-number">0.1</span> What is a conceptual introduction?</a></li>
<li><a href="index.html#how-to-read-a-table-or-matrix"><span class="toc-section-number">0.2</span> How to read a table or matrix</a></li>
<li><a href="index.html#the-very-basic-math"><span class="toc-section-number">0.3</span> The Very Basic Math</a></li>
<li><a href="index.html#inspiration-and-acknowledgments"><span class="toc-section-number">0.4</span> Inspiration and Acknowledgments</a></li>
</ul></li>
<li class="has-sub"><a href="intro.html#intro"><span class="toc-section-number">1</span> Introduction</a><ul>
<li><a href="intro.html#some-basic-conceptual-ingredients"><span class="toc-section-number">1.1</span> Some Basic Conceptual Ingredients</a></li>
<li><a href="intro.html#rationality---the-descriptive-and-normative"><span class="toc-section-number">1.2</span> Rationality - the Descriptive and Normative</a></li>
<li><a href="intro.html#uncertainty"><span class="toc-section-number">1.3</span> Uncertainty</a></li>
<li><a href="intro.html#practical-and-theoretical-problems"><span class="toc-section-number">1.4</span> Practical and Theoretical Problems</a></li>
<li><a href="intro.html#summary"><span class="toc-section-number">1.5</span> Summary</a></li>
<li><a href="intro.html#exercises">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="ranking.html#ranking"><span class="toc-section-number">2</span> Ranking</a><ul>
<li><a href="ranking.html#maximin-and-maximax"><span class="toc-section-number">2.1</span> Maximin and Maximax</a></li>
<li><a href="ranking.html#the-dominance-principle"><span class="toc-section-number">2.2</span> The Dominance Principle</a></li>
<li><a href="ranking.html#more-than-two-options-and-two-states"><span class="toc-section-number">2.3</span> More than two options and two states</a></li>
<li><a href="ranking.html#non-unique-recommendations"><span class="toc-section-number">2.4</span> Non-Unique Recommendations</a></li>
<li><a href="ranking.html#independence-of-options-and-states"><span class="toc-section-number">2.5</span> Independence of Options and States</a></li>
<li><a href="ranking.html#exercises-1">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="transitivity-and-completeness.html#transitivity-and-completeness"><span class="toc-section-number">3</span> Transitivity and Completeness</a><ul>
<li><a href="transitivity-and-completeness.html#notation"><span class="toc-section-number">3.1</span> Notation</a></li>
<li><a href="transitivity-and-completeness.html#money-pump-arguments-for-axioms"><span class="toc-section-number">3.2</span> Money Pump Arguments for Axioms</a></li>
<li><a href="transitivity-and-completeness.html#arguments-for-transitivity"><span class="toc-section-number">3.3</span> Arguments for Transitivity</a></li>
<li><a href="transitivity-and-completeness.html#arguments-for-completeness"><span class="toc-section-number">3.4</span> Arguments for Completeness</a></li>
<li class="has-sub"><a href="transitivity-and-completeness.html#social-choice"><span class="toc-section-number">3.5</span> Social Choice</a><ul>
<li><a href="transitivity-and-completeness.html#group-decisions-are-not-mere-sets-of-individual-decisions"><span class="toc-section-number">3.5.1</span> Group decisions are not mere sets of individual decisions</a></li>
<li><a href="transitivity-and-completeness.html#plurality-and-runoffs"><span class="toc-section-number">3.5.2</span> Plurality and Runoffs</a></li>
<li><a href="transitivity-and-completeness.html#the-borda-count-and-an-impossible-task"><span class="toc-section-number">3.5.3</span> The Borda Count and an Impossible Task</a></li>
</ul></li>
<li><a href="transitivity-and-completeness.html#limitations-and-key-take-aways"><span class="toc-section-number">3.6</span> Limitations and Key Take Aways</a></li>
<li><a href="transitivity-and-completeness.html#exercises-2">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="utilities.html#utilities"><span class="toc-section-number">4</span> Utilities</a><ul>
<li><a href="utilities.html#creating-an-interval-scale"><span class="toc-section-number">4.1</span> Creating an Interval Scale</a></li>
<li class="has-sub"><a href="utilities.html#what-do-the-numbers-mean"><span class="toc-section-number">4.2</span> What do the numbers mean?</a><ul>
<li><a href="utilities.html#material-and-money"><span class="toc-section-number">4.2.1</span> Material and money</a></li>
<li><a href="utilities.html#hedonism-and-experience-based-theories"><span class="toc-section-number">4.2.2</span> Hedonism and Experience-based Theories</a></li>
<li><a href="utilities.html#objective-list-theories"><span class="toc-section-number">4.2.3</span> Objective List Theories</a></li>
<li><a href="utilities.html#preference-based-theories"><span class="toc-section-number">4.2.4</span> Preference-based Theories</a></li>
</ul></li>
<li class="has-sub"><a href="utilities.html#applications-and-challenges"><span class="toc-section-number">4.3</span> Applications and Challenges</a><ul>
<li><a href="utilities.html#minimize-regret"><span class="toc-section-number">4.3.1</span> Minimize Regret</a></li>
<li><a href="utilities.html#multiattribute-approach"><span class="toc-section-number">4.3.2</span> Multiattribute Approach</a></li>
</ul></li>
<li><a href="utilities.html#more-challenges-and-final-remarks"><span class="toc-section-number">4.4</span> More Challenges and Final Remarks</a></li>
<li><a href="utilities.html#exercises-3">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="expected-utilities.html#expected-utilities"><span class="toc-section-number">5</span> Expected Utilities</a><ul>
<li class="has-sub"><a href="expected-utilities.html#expected-utility-by-example"><span class="toc-section-number">5.1</span> Expected Utility by Example</a><ul>
<li><a href="expected-utilities.html#step-one-compute-eu-of-each-option"><span class="toc-section-number">5.1.1</span> Step One: Compute EU of each option</a></li>
<li><a href="expected-utilities.html#step-two-find-maximum-eu"><span class="toc-section-number">5.1.2</span> Step Two: Find maximum EU</a></li>
</ul></li>
<li><a href="expected-utilities.html#meu-maximize-expected-utility-strategy"><span class="toc-section-number">5.2</span> (MEU) Maximize Expected Utility Strategy</a></li>
<li><a href="expected-utilities.html#application-combining-meu-and-the-multi-attribute-approach"><span class="toc-section-number">5.3</span> Application: Combining MEU and the Multi-Attribute Approach</a></li>
<li><a href="expected-utilities.html#pascals-wager"><span class="toc-section-number">5.4</span> Pascal’s Wager</a></li>
<li><a href="expected-utilities.html#key-take-aways"><span class="toc-section-number">5.5</span> Key Take Aways</a></li>
<li><a href="expected-utilities.html#exercises-4">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="arguments-about-meu.html#arguments-about-meu"><span class="toc-section-number">6</span> Arguments about MEU</a><ul>
<li><a href="arguments-about-meu.html#the-domain-of-meu"><span class="toc-section-number">6.1</span> The Domain of MEU</a></li>
<li><a href="arguments-about-meu.html#long-run-arguments-for-meu"><span class="toc-section-number">6.2</span> Long Run Arguments for MEU</a></li>
<li><a href="arguments-about-meu.html#two-kinds-of-arguments-against-meu"><span class="toc-section-number">6.3</span> Two Kinds of Arguments Against MEU</a></li>
<li class="has-sub"><a href="arguments-about-meu.html#arguments-against-normative-meu"><span class="toc-section-number">6.4</span> Arguments Against Normative MEU</a><ul>
<li><a href="arguments-about-meu.html#allais-paradox"><span class="toc-section-number">6.4.1</span> Allais Paradox</a></li>
<li><a href="arguments-about-meu.html#ellsbergs-paradox"><span class="toc-section-number">6.4.2</span> Ellsberg’s Paradox</a></li>
<li><a href="arguments-about-meu.html#the-sure-thing-principle"><span class="toc-section-number">6.4.3</span> The Sure Thing Principle</a></li>
<li><a href="arguments-about-meu.html#st-petersburg-paradox"><span class="toc-section-number">6.4.4</span> St Petersburg Paradox</a></li>
<li><a href="arguments-about-meu.html#the-two-envelope-paradox"><span class="toc-section-number">6.4.5</span> The Two Envelope Paradox</a></li>
</ul></li>
<li class="has-sub"><a href="arguments-about-meu.html#arguments-against-descriptive-meu"><span class="toc-section-number">6.5</span> Arguments Against Descriptive MEU</a><ul>
<li><a href="arguments-about-meu.html#risk-aversion"><span class="toc-section-number">6.5.1</span> Risk Aversion</a></li>
<li><a href="arguments-about-meu.html#loss-aversion"><span class="toc-section-number">6.5.2</span> Loss Aversion</a></li>
<li><a href="arguments-about-meu.html#endowment-effect"><span class="toc-section-number">6.5.3</span> Endowment Effect</a></li>
<li><a href="arguments-about-meu.html#prospect-theory"><span class="toc-section-number">6.5.4</span> Prospect Theory</a></li>
<li><a href="arguments-about-meu.html#weighting-effects-and-why-they-matter"><span class="toc-section-number">6.5.5</span> Weighting Effects and Why They Matter</a></li>
</ul></li>
<li><a href="arguments-about-meu.html#summary-1"><span class="toc-section-number">6.6</span> Summary</a></li>
<li><a href="arguments-about-meu.html#exercises-5"><span class="toc-section-number">6.7</span> Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="intervention.html#intervention"><span class="toc-section-number">7</span> Intervention</a><ul>
<li><a href="intervention.html#causal-models"><span class="toc-section-number">7.1</span> Causal Models</a></li>
<li><a href="intervention.html#common-causes"><span class="toc-section-number">7.2</span> Common Causes</a></li>
<li><a href="intervention.html#application-to-newcomb-like-problems"><span class="toc-section-number">7.3</span> Application to Newcomb-like Problems</a></li>
<li><a href="intervention.html#the-locus-of-choice-and-types-of-decision-theories"><span class="toc-section-number">7.4</span> The Locus of Choice and Types of Decision Theories</a></li>
<li><a href="intervention.html#exercises-6"><span class="toc-section-number">7.5</span> Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="probabilities.html#probabilities"><span class="toc-section-number">8</span> Probabilities</a><ul>
<li><a href="probabilities.html#measures"><span class="toc-section-number">8.1</span> Measures</a></li>
<li><a href="probabilities.html#normalized-measures"><span class="toc-section-number">8.2</span> Normalized Measures</a></li>
<li class="has-sub"><a href="probabilities.html#possibilities-and-truth-tables"><span class="toc-section-number">8.3</span> Possibilities and Truth Tables</a><ul>
<li><a href="probabilities.html#tautologies"><span class="toc-section-number">8.3.1</span> Tautologies</a></li>
<li><a href="probabilities.html#equivalence"><span class="toc-section-number">8.3.2</span> Equivalence</a></li>
<li><a href="probabilities.html#inconsistency"><span class="toc-section-number">8.3.3</span> Inconsistency</a></li>
<li><a href="probabilities.html#logic-probabilities"><span class="toc-section-number">8.3.4</span> Logic Probabilities</a></li>
</ul></li>
<li class="has-sub"><a href="probabilities.html#exercises-7"><span class="toc-section-number">8.4</span> Exercises</a><ul>
<li><a href="probabilities.html#proporitions-to-probabilities"><span class="toc-section-number">8.4.1</span> Proporitions to Probabilities</a></li>
<li><a href="probabilities.html#the-conjunction-fallacy"><span class="toc-section-number">8.4.2</span> The Conjunction Fallacy</a></li>
<li><a href="probabilities.html#atomic-vs-conjunctions"><span class="toc-section-number">8.4.3</span> Atomic vs Conjunctions</a></li>
<li><a href="probabilities.html#disjunction"><span class="toc-section-number">8.4.4</span> Disjunction</a></li>
<li><a href="probabilities.html#conjunctions-and-disjunctions"><span class="toc-section-number">8.4.5</span> Conjunctions and Disjunctions</a></li>
<li><a href="probabilities.html#linda-again"><span class="toc-section-number">8.4.6</span> Linda (again)</a></li>
</ul></li>
</ul></li>
<li><a href="odds-and-actions.html#odds-and-actions"><span class="toc-section-number">9</span> Odds and Actions</a></li>
<li><a href="conditional-probabilities-and-likelihoods.html#conditional-probabilities-and-likelihoods"><span class="toc-section-number">10</span> Conditional Probabilities and Likelihoods</a></li>
<li><a href="base-rates-priors-and-bayes-rule.html#base-rates-priors-and-bayes-rule"><span class="toc-section-number">11</span> Base Rates, Priors, and Bayes Rule</a></li>
<li><a href="learning-and-motivated-reasoning.html#learning-and-motivated-reasoning"><span class="toc-section-number">12</span> Learning and Motivated Reasoning</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="probabilities" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Probabilities</h1>
<p>We have come to the point where it will no longer be enough to work with our intuitive notion of probability. If we want to go beyond toy decision problems, like the one’s we’ve been covered, and model decisions that are more like the ones we more frequently face, we’ll need to have a sufficiently robust understanding of probability. For example, one of the main things we’ll want to be able to do is update our beliefs given new information, which effectively amounts to knowing how to update probabilities.</p>
<p>In this chapter we’re going to learn what it means when we say that a probability function is a <em>normalized measure over a possibility space</em>. There are three parts here: i) what is it for a function to be a measure, ii) what is a normalized measure, and iii) what is a possibility space.</p>
<div id="measures" class="section level2">
<h2><span class="header-section-number">8.1</span> Measures</h2>
<p>A function is a mapping from an input to an output. There can be many inputs that are mapped to one output, but to be a function the mapping cannot assign more than one output to an input. We typically think of functions as having numbers as inputs and outputs, but that doesn’t have to be the case. In fact, as we’ll see, probability functions will have a number as an output, but have non-numbers as inputs.</p>
<p>Consider Scotland. Scotland is known for its whisky. There are six regions (depending on who you ask) where whisky is distilled.</p>
<p>We can represent functions with tables. Let’s suppose we have a function that takes distilling regions of Scotland as input and the number of distilleries as output.</p>
<table>
<thead>
<tr class="header">
<th align="center">Input</th>
<th align="center">Output</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Highlands</td>
<td align="center">27</td>
</tr>
<tr class="even">
<td align="center">Speyside</td>
<td align="center">62</td>
</tr>
<tr class="odd">
<td align="center">Lowlands</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">Campbeltown</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center">Islay</td>
<td align="center">8</td>
</tr>
<tr class="even">
<td align="center">Islands</td>
<td align="center">7</td>
</tr>
</tbody>
</table>
<p>Notice that there are two inputs that get mapped onto the same output (Lowlands and Campbeltown), but no input has any more or less than one output (e.g., it’s not the case that Islay has both 8 and 7 distilleries).</p>
<p>What we want to know next is what it means for a function to be a measure. First, the function has to have non-negative numbers as output. Our example meets this condition. Second, the input is some space that can have ‘regions’ or subsets. For example, we can organize our distilling regions into those that are on the mainland (the first four in our table) and those not on the mainland (i.e., Islay and Islands). Alternatively, we could group the list into those whose name starts with one of the first ten letters of the alphabet, those that start with `S’, and then the rest. The specifics here don’t matter, just that different subsets are possible.</p>
<p>Third, and this important property is called <em>additivity</em>, is that the measure of a subset is the sum of the measures of the members that make up the subset. For example, suppose we’re considering the mainland distillery regions (the first four on our list). Then the number of distilleries on the mainland is just the sum of the distilleries in the regions of Highlands, Speyside, Lowlands, and Campbeltown (95).</p>
<p>It doesn’t really matter how we decide to group things. We could decide that the ‘groups’ are just the members themselves. In that case, there is just one number to consider. Or we could consider the entire input as the subset (here ‘subset’ doesn’t indicate a strictly smaller set - in set theoretic speak, we say that a set is a subset of itself). For example, the number of distilleries in Scotland is, according to our table, 110 (i.e., the sum of each region).</p>
<p>Not all functions are measures. That is, some functions fail to be additive. For example, let’s suppose we have a function from distilling regions to the proportion of distilleries owned by multinational companies (these numbers are not necessarily accurate).</p>
<table>
<thead>
<tr class="header">
<th align="center">Input</th>
<th align="right">Output (proportion of owned by corps.)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Highlands</td>
<td align="right">0.6</td>
</tr>
<tr class="even">
<td align="center">Speyside</td>
<td align="right">0.4</td>
</tr>
<tr class="odd">
<td align="center">Lowlands</td>
<td align="right">0.3</td>
</tr>
<tr class="even">
<td align="center">Campbeltown</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="center">Islay</td>
<td align="right">0.25</td>
</tr>
<tr class="even">
<td align="center">Islands</td>
<td align="right">0.4</td>
</tr>
</tbody>
</table>
<p>Now let’s say we want to ask what proportion of the mainland distilleries are owned by multinational companies. We can’t do this just by looking at the table above. Adding up proportions won’t work: it would lead to the absurd result that the proportion of mainland distilleries owned by international companies is 1.3, that is, 130%. But it’s impossible to own more than 100% of the mainland distilleries, not to mention own more than 100% of anything! In general, proportions do not meet the Additivity property and thus cannot serve as the basis for measures. Typical examples of measures include length, area, and volume.</p>
</div>
<div id="normalized-measures" class="section level2">
<h2><span class="header-section-number">8.2</span> Normalized Measures</h2>
<p>The ‘universe’ of a function is the entire collection of inputs. In our whisky example above, the universe of our function is the set of distillery regions in Scotland. We could have defined the universe of our function differently. For example, we might have a different function whose universe is the set of countries that have distilleries, including Scotland, Ireland, the United States, Canada, Japan, etc. Also, the universe of a function doesn’t have to correspond to physical space. We could have a function with a universe of taste characteristics, like sweet, smoky, earthy, rich, peppery, floral, etc. These are not located in space like distilleries, but are rather properties of how a whisky is perceived by taste.</p>
<p>A <em>normalized</em> measure function is a measure function that gives a value of 1 to its universe. By doing so, the measure of every subset can be understood as a proportion of the universe of the function. Any measure can be `normalized’ by dividing the value of each output by the value of the whole universe. For example, we can normalize the function represented in the table below by dividing each output number by the sum of all outputs (110). That would give us the normalized values in the following table (rounded to four decimal places).</p>
<table>
<thead>
<tr class="header">
<th align="center">Input</th>
<th align="center">Output</th>
<th align="center">Normalized</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Highlands</td>
<td align="center">27</td>
<td align="center">0.2455</td>
</tr>
<tr class="even">
<td align="center">Speyside</td>
<td align="center">62</td>
<td align="center">0.5636</td>
</tr>
<tr class="odd">
<td align="center">Lowlands</td>
<td align="center">3</td>
<td align="center">0.0273</td>
</tr>
<tr class="even">
<td align="center">Campbeltown</td>
<td align="center">3</td>
<td align="center">0.0273</td>
</tr>
<tr class="odd">
<td align="center">Islay</td>
<td align="center">8</td>
<td align="center">0.0727</td>
</tr>
<tr class="even">
<td align="center">Islands</td>
<td align="center">7</td>
<td align="center">0.0636</td>
</tr>
</tbody>
</table>
<p>Notice that this normalized function satisfies the property of being additive. We can use the table to answer the question of what proportion of all distilleries in Scotland are on the mainland by adding up the normalized values (keeping in mind that we will need to correct for errors from having rounded the values). This works because the sum of all the normalized values add up to 1. This is unlike the function represented in the previous table where the proportions do not sum to 1.</p>
<p>Normalizing is an important step in taking data from the world and turning it into probability functions. Sometimes the universe of a function is not very well defined. In that case, it will not be possible to normalize. So one important lesson for interpreting results of some data is to understand what the relevant universe is supposed to be.</p>
</div>
<div id="possibilities-and-truth-tables" class="section level2">
<h2><span class="header-section-number">8.3</span> Possibilities and Truth Tables</h2>
<p>Let’s look at how to build a probability function. We’ll start with a really simple example. Suppose we have a fair coin and you’re going to flip it twice. In the first flip there are two possible outcomes: heads (H) or tails (T). In the second flip there are again two possible outcomes: H or T. For two flips of the coin then, there are a total of four possible outcomes: HH, TH, HT, TT. We can keep track of these in a table.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center">Flip 1</th>
<th align="center">Flip 2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Outcome 1</td>
<td align="center">H</td>
<td align="center">H</td>
</tr>
<tr class="even">
<td>Outcome 2</td>
<td align="center">T</td>
<td align="center">H</td>
</tr>
<tr class="odd">
<td>Outcome 3</td>
<td align="center">H</td>
<td align="center">T</td>
</tr>
<tr class="even">
<td>Outcome 4</td>
<td align="center">T</td>
<td align="center">T</td>
</tr>
</tbody>
</table>
<p>If we were to flip the coin a third time, we would have 8 possible outcomes, which we can also collect in a table</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center">Flip 1</th>
<th align="center">Flip 2</th>
<th align="center">Flip 3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Outcome 1</td>
<td align="center">H</td>
<td align="center">H</td>
<td align="center">H</td>
</tr>
<tr class="even">
<td>Outcome 2</td>
<td align="center">T</td>
<td align="center">H</td>
<td align="center">H</td>
</tr>
<tr class="odd">
<td>Outcome 3</td>
<td align="center">H</td>
<td align="center">T</td>
<td align="center">H</td>
</tr>
<tr class="even">
<td>Outcome 4</td>
<td align="center">T</td>
<td align="center">T</td>
<td align="center">H</td>
</tr>
<tr class="odd">
<td>Outcome 5</td>
<td align="center">H</td>
<td align="center">H</td>
<td align="center">T</td>
</tr>
<tr class="even">
<td>Outcome 6</td>
<td align="center">T</td>
<td align="center">H</td>
<td align="center">T</td>
</tr>
<tr class="odd">
<td>Outcome 7</td>
<td align="center">H</td>
<td align="center">T</td>
<td align="center">T</td>
</tr>
<tr class="even">
<td>Outcome 8</td>
<td align="center">T</td>
<td align="center">T</td>
<td align="center">T</td>
</tr>
</tbody>
</table>
<p>If we were to flip the coin four times, there would 16 possibilities. Each time we add an additional flip, the number of possibilities doubles in total. That is, where <span class="math inline">\(n\)</span> is the number of coin flips, the total number of possible outcomes is <span class="math inline">\(2^n\)</span>.</p>
<p>Although this example is simple, it turns out to be a really fruitful way of modeling lots of other examples that have the same structure. For example, philosophers love logic and thinking about the world in terms of statements or propositions that are either true or false. Suppose we have three different propositions: P, Q, and R.</p>
<ul>
<li>P - "Bert drinks beer on Fridays.’’</li>
<li>Q - "Bert drinks wine on Fridays.’’</li>
<li>R - "Bert drinks Scotch whisky on Fridays.’’</li>
</ul>
<p>For simplicity, let’s assume that P is true if on the majority of Fridays I have a beer, and is false otherwise. Similarly for Q and R. In the real world each of these propositions has a unique truth value. Our interest here, however, is not just what is true, but the space of possibilities. In this case, each proposition has the possibility of being true (T) or false (F). Following the coin flip example, there are in total eight possibilities. We can organize the possibilities in what logicians call a truth table.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center">P</th>
<th align="center">Q</th>
<th align="center">R</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td align="center">F</td>
<td align="center">F</td>
<td align="center">F</td>
</tr>
<tr class="even">
<td></td>
<td align="center">T</td>
<td align="center">F</td>
<td align="center">F</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">F</td>
<td align="center">T</td>
<td align="center">F</td>
</tr>
<tr class="even">
<td></td>
<td align="center">T</td>
<td align="center">T</td>
<td align="center">F</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">F</td>
<td align="center">F</td>
<td align="center">T</td>
</tr>
<tr class="even">
<td></td>
<td align="center">T</td>
<td align="center">F</td>
<td align="center">T</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">F</td>
<td align="center">T</td>
<td align="center">T</td>
</tr>
<tr class="even">
<td></td>
<td align="center">T</td>
<td align="center">T</td>
<td align="center">T</td>
</tr>
</tbody>
</table>
<p>These eight possibilities provide the foundation for creating a probability function. What we first need to do is make sure that we have a measure. Let’s say we give the following numbers to each row in the truth table. Where the numbers come from is not important to illustrate the point. But we can imagine, at least roughly speaking, that the universe of the function is all Fridays, and the outputs represent the fraction of times I reported what I had to drink. Notice that if we sum up the output values, we get 1. So, we have a measure, and it’s a normalized measure.</p>
<table>
<thead>
<tr class="header">
<th align="center">Probability</th>
<th align="center">P</th>
<th align="center">Q</th>
<th align="left">R</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">0.0002</td>
<td align="center">F</td>
<td align="center">F</td>
<td align="left">F</td>
</tr>
<tr class="even">
<td align="center">0.001</td>
<td align="center">T</td>
<td align="center">F</td>
<td align="left">F</td>
</tr>
<tr class="odd">
<td align="center">0.0008</td>
<td align="center">F</td>
<td align="center">T</td>
<td align="left">F</td>
</tr>
<tr class="even">
<td align="center">0.008</td>
<td align="center">T</td>
<td align="center">T</td>
<td align="left">F</td>
</tr>
<tr class="odd">
<td align="center">0.08</td>
<td align="center">F</td>
<td align="center">F</td>
<td align="left">T</td>
</tr>
<tr class="even">
<td align="center">0.1</td>
<td align="center">T</td>
<td align="center">F</td>
<td align="left">T</td>
</tr>
<tr class="odd">
<td align="center">0.01</td>
<td align="center">F</td>
<td align="center">T</td>
<td align="left">T</td>
</tr>
<tr class="even">
<td align="center">0.8</td>
<td align="center">T</td>
<td align="center">T</td>
<td align="left">T</td>
</tr>
</tbody>
</table>
<p>We can now use this table to ask questions about the probability that a proposition is true. To do that, we look at all the rows where the proposition in question is true, and then add up the output values. For example, suppose we are interested in the probability that P is true (i.e., the probability that Bert drinks beer on a Friday). Notice that P is true in rows 2, 4, 6, and 8. So we would compute <span class="math inline">\(0.001+0.008+0.1+0.8\)</span> which is 0.909. That is, there is a 90.9% that Bert drinks beer on a Friday.</p>
<p>We aren’t limited to asking the probabilities that a single proposition is true. Sometimes we’ll want to ask what the probability is that both P and R is true, or that either P or R is true, or that P is false. These are all examples of more complex sentences. Logicians have a way of expressing these types of complex sentences. They call them conjunctions, disjunctions, and negations, respectively. There are some handy symbols used too:</p>
<p>‘P<span class="math inline">\(\wedge\)</span>Q’ means ‘P and Q’ (also called conjunction)
‘P<span class="math inline">\(\vee\)</span>Q’ means ‘P or Q’ (also called disjunction)
‘<span class="math inline">\(\neg\)</span>P’ means ‘not P’ (also called negation)</p>
<p>What’s really handy about these formulations is that the truth values of the complex sentences can be fixed by the truth values of the components. For example, the rule for conjunction is</p>
<table>
<thead>
<tr class="header">
<th align="right">P</th>
<th align="center">Q</th>
<th align="center">P<span class="math inline">\(\wedge\)</span>Q</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">T</td>
<td align="center">T</td>
<td align="center">T</td>
</tr>
<tr class="even">
<td align="right">T</td>
<td align="center">F</td>
<td align="center">F</td>
</tr>
<tr class="odd">
<td align="right">F</td>
<td align="center">T</td>
<td align="center">F</td>
</tr>
<tr class="even">
<td align="right">F</td>
<td align="center">F</td>
<td align="center">F</td>
</tr>
</tbody>
</table>
<p>As you may guess, the truth table for negation is pretty simple. The truth value is simply reversed.</p>
<table>
<thead>
<tr class="header">
<th align="right">P</th>
<th align="left"><span class="math inline">\(\neg\)</span>P</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">T</td>
<td align="left">F</td>
</tr>
<tr class="even">
<td align="right">F</td>
<td align="left">T</td>
</tr>
</tbody>
</table>
<p>For disjunction the truth value of the whole sentence is given by the following table.</p>
<table>
<thead>
<tr class="header">
<th align="center">P</th>
<th align="center">Q</th>
<th align="center">P<span class="math inline">\(\vee\)</span>Q</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">T</td>
<td align="center">T</td>
<td align="center">T</td>
</tr>
<tr class="even">
<td align="center">T</td>
<td align="center">F</td>
<td align="center">T</td>
</tr>
<tr class="odd">
<td align="center">F</td>
<td align="center">T</td>
<td align="center">T</td>
</tr>
<tr class="even">
<td align="center">F</td>
<td align="center">F</td>
<td align="center">F</td>
</tr>
</tbody>
</table>
<p>Notice that this is an inclusive interpretation of ‘or’ which means that disjunction assumes by default that when both component sentences are true then the whole sentence is true. For example, if you are asked, “Do you want ketchup or mustard on your burger” there’s nothing contradictory about saying that you want both. It’s easy enough to express the exclusive version ‘or’ by say something like ‘P or Q, and not both’. Formally we would write ‘(P<span class="math inline">\(\vee\)</span>Q) <span class="math inline">\(\wedge\)</span> <span class="math inline">\(\neg\)</span>(P<span class="math inline">\(\wedge\)</span>Q)’.</p>
<p>We can use the truth table definitions of conjunction, disjunction, and negation to determine the possible truth values of a complex sentence. Consider for example the sentence ‘(P<span class="math inline">\(\vee\)</span>R) <span class="math inline">\(\wedge\)</span> <span class="math inline">\(\neg\)</span>Q’ which can be interpreted as “On Fridays Bert drinks beer or he drinks Scotch whisky, but he doesn’t drink wine.’’ (Note that”but’’ expresses "and’’ with the addition of some flare to highlight a contrast.) Using the rules for <span class="math inline">\(\wedge\)</span>, <span class="math inline">\(\vee\)</span>, and <span class="math inline">\(\neg\)</span> we get the table below. Notice that the whole complex sentence is a conjunction, where the left conjunct is made out of a disjunction (P<span class="math inline">\(\vee\)</span>R), and the right conjunct is made out of a negation (<span class="math inline">\(\neg\)</span>Q). So we have to work from the smallest parts up to the larger parts, which means that we first evaluate ‘(P<span class="math inline">\(\vee\)</span>R)’, then we evaluate ‘<span class="math inline">\(\neg\)</span>Q’, and then we can do the column of truth values under ‘<span class="math inline">\(\wedge\)</span>’ (which have been boldfaced to indicate these truth values are under the main connective).</p>
<table>
<thead>
<tr class="header">
<th align="center">Probability</th>
<th align="center">P</th>
<th align="center">Q</th>
<th align="center">R</th>
<th align="center">(P<span class="math inline">\(\vee\)</span>R) <span class="math inline">\(\wedge\)</span> <span class="math inline">\(\neg\)</span>Q</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">0.0002</td>
<td align="center">F</td>
<td align="center">F</td>
<td align="center">F</td>
<td align="center">F <span class="math inline">\(~~\)</span> <strong>F</strong> T</td>
</tr>
<tr class="even">
<td align="center">0.001</td>
<td align="center">T</td>
<td align="center">F</td>
<td align="center">F</td>
<td align="center">T <span class="math inline">\(~~\)</span> <strong>T</strong> T</td>
</tr>
<tr class="odd">
<td align="center">0.0008</td>
<td align="center">F</td>
<td align="center">T</td>
<td align="center">F</td>
<td align="center">F <span class="math inline">\(~~\)</span> <strong>F</strong> F</td>
</tr>
<tr class="even">
<td align="center">0.008</td>
<td align="center">T</td>
<td align="center">T</td>
<td align="center">F</td>
<td align="center">T <span class="math inline">\(~~\)</span> <strong>F</strong> F</td>
</tr>
<tr class="odd">
<td align="center">0.08</td>
<td align="center">F</td>
<td align="center">F</td>
<td align="center">T</td>
<td align="center">T <span class="math inline">\(~~\)</span> <strong>T</strong> T</td>
</tr>
<tr class="even">
<td align="center">0.1</td>
<td align="center">T</td>
<td align="center">F</td>
<td align="center">T</td>
<td align="center">T <span class="math inline">\(~~\)</span> <strong>T</strong> T</td>
</tr>
<tr class="odd">
<td align="center">0.01</td>
<td align="center">F</td>
<td align="center">T</td>
<td align="center">T</td>
<td align="center">T <span class="math inline">\(~~\)</span> <strong>F</strong> F</td>
</tr>
<tr class="even">
<td align="center">0.8</td>
<td align="center">T</td>
<td align="center">T</td>
<td align="center">T</td>
<td align="center">T <span class="math inline">\(~~\)</span> <strong>F</strong> F</td>
</tr>
</tbody>
</table>
<p>Notice that the complex sentence is true on rows 2, 5, and 6. So as an example, if P is true but Q and R are false, then P<span class="math inline">\(\vee\)</span>R) <span class="math inline">\(\wedge\)</span> <span class="math inline">\(\neg\)</span>Q is true (this is row two).</p>
<p>If we want to calculate what the probability is that ‘(P<span class="math inline">\(\vee\)</span>R) <span class="math inline">\(\wedge\)</span> <span class="math inline">\(\neg\)</span>Q’ is true, all we need to do is add up the probabilities that correspond to each row. This would be <span class="math inline">\(0.001+0.08+0.1 = 0.181\)</span>. That is, there is an 18.1% chance that on Fridays Bert drinks beer or Scotch whisky, but doesn’t drink wine.</p>
<p>It is worth pointing out several features about probabilities that correspond to some important logical concepts: tautologies, equivalence, entailment, and inconsistency. In fact, these will be directly connected to the axioms that are typically used to define probabilities. So it’s worth paying special attention here, as we’ll use these results frequently going forward.</p>
<div id="tautologies" class="section level3">
<h3><span class="header-section-number">8.3.1</span> Tautologies</h3>
<p>A tautology is a sentence that is true across every possibility. The simplest example of this is a sentence ‘P<span class="math inline">\(\vee\)</span> <span class="math inline">\(\neg\)</span>P’ which says ‘Either Bert drinks beers on Fridays or he doesn’t’. Yes, there are complications regarding what it means to satisfy the property ‘drinks beer on Fridays’ - does it have to be at least more than half of all Fridays? Note that whatever line or standard you pick, that will be the same one for the negation of the sentence. So if the standard is that `Bert drinks beers on Fridays’ is true just as long as he does on 75% of all Fridays, then that sentence is false if he drinks them only on every other Friday (i.e. 50% of them).</p>
<p>Notice that when we take the disjunction of a sentence and the negation of that sentence, the column under the main connective (the disjunction) will be true on every row. Let’s look at the truth table for ‘P<span class="math inline">\(\vee\)</span> <span class="math inline">\(\neg\)</span>P’ (notice we evaluate ‘<span class="math inline">\(\neg\)</span>P’ first, then the disjunction):</p>
<table>
<thead>
<tr class="header">
<th align="center">P</th>
<th align="center">P <span class="math inline">\(\vee\)</span> <span class="math inline">\(\neg\)</span>P</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">T</td>
<td align="center"><strong>T<span class="math inline">\(~\)</span></strong> F</td>
</tr>
<tr class="even">
<td align="center">F</td>
<td align="center"><strong>T<span class="math inline">\(~\)</span></strong> T</td>
</tr>
</tbody>
</table>
<p>Recall that we determined the probability that ‘P’ is true by adding up all the probabilities in the rows were ‘P’ is true. If we use the same table to determine the probability that ‘P’ is false (i.e., we add up all the numbers in the rows where `P’ is false) then we get the following probabilities:</p>
<table>
<thead>
<tr class="header">
<th align="center">Probabilities</th>
<th align="center">P</th>
<th align="center">P <span class="math inline">\(\vee\)</span> <span class="math inline">\(\neg\)</span>P</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">0.909</td>
<td align="center">T</td>
<td align="center"><strong>T<span class="math inline">\(~\)</span></strong> F</td>
</tr>
<tr class="even">
<td align="center">0.091</td>
<td align="center">F</td>
<td align="center"><strong>T<span class="math inline">\(~\)</span></strong> T</td>
</tr>
</tbody>
</table>
<p>Now if we add up all the rows where ‘P<span class="math inline">\(\vee\)</span> <span class="math inline">\(\neg\)</span>P’ is true, which are 1 and 2 (and there are no other rows) we get a total of 1. This makes sense upon some reflection. A tautology is always true, i.e., it is true in every possibility. We also said that a probability is a normalized measure, where the universe of the function added to 1. Since a tautology has us adding up the probabilities across all the rows, it’s not surprising that they sum to 1. In brief, the probability that a tautology is true is 1.</p>
</div>
<div id="equivalence" class="section level3">
<h3><span class="header-section-number">8.3.2</span> Equivalence</h3>
<p>Some statements are equivalent. What we mean by that is that they say the same thing, even if they differ in how they say it. For example, the sentence ‘Schnee ist weiss’ expresses the same proposition that is said in ‘snow is white’.</p>
<p>In symbolic logic we can use truth tables to check whether two sentences are equivalent. Consider the sentences ‘<span class="math inline">\(\neg\)</span>(P <span class="math inline">\(\wedge\)</span> Q)’ and ‘<span class="math inline">\(\neg\)</span>P <span class="math inline">\(\vee\)</span> <span class="math inline">\(\neg\)</span> Q’. The first one reads as ‘It’s not the case that both Bert drinks beer on Fridays and drinks wine’. Notice that the negation is being applied to the conjunction. The second sentence reads `Either it’s not the case that Bert drinks beer on Fridays or it’s not the case that Bert drinks wine on Fridays’. Notice that this second sentence is a disjunction that has two negations as component sentences.</p>
<p>In order to test whether two sentences are equivalent, we build a truth table and evaluate each sentence. Then we check to see whether the columns under the main connective of the sentences are identical. If they are, that means that in every possibility their truth values match, i.e., they are equivalent. When one sentence is true, so is the other, and when one is false, so is the other. When we look at the truth tables for ‘<span class="math inline">\(\neg\)</span>(P <span class="math inline">\(\wedge\)</span> Q)’ and ‘<span class="math inline">\(\neg\)</span>P <span class="math inline">\(\vee\)</span> <span class="math inline">\(\neg\)</span> Q’ we see that they are indeed equivalent:</p>
<table>
<thead>
<tr class="header">
<th align="center">P</th>
<th align="center">Q</th>
<th align="center"><span class="math inline">\(\neg\)</span>(P <span class="math inline">\(\wedge\)</span> Q)</th>
<th align="center"><span class="math inline">\(\neg\)</span>P <span class="math inline">\(\vee\)</span> <span class="math inline">\(\neg\)</span> Q</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">T</td>
<td align="center">T</td>
<td align="center">F<span class="math inline">\(~~~~~~~~~~\)</span></td>
<td align="center">F</td>
</tr>
<tr class="even">
<td align="center">T</td>
<td align="center">F</td>
<td align="center">T<span class="math inline">\(~~~~~~~~~~\)</span></td>
<td align="center">T</td>
</tr>
<tr class="odd">
<td align="center">F</td>
<td align="center">T</td>
<td align="center">T<span class="math inline">\(~~~~~~~~~~\)</span></td>
<td align="center">T</td>
</tr>
<tr class="even">
<td align="center">F</td>
<td align="center">F</td>
<td align="center">T<span class="math inline">\(~~~~~~~~~~\)</span></td>
<td align="center">T</td>
</tr>
</tbody>
</table>
<p>One of the most important concepts in logic is that of <strong>validity</strong>. Validity is a property of arguments. An argument is a series of statements, where one is designated the conclusion and the other statements the premises (these are intended to support the conclusion). An argument is valid when <em>if</em> the premises are true, then the conclusion <em>has</em> to be true. Put differently: an argument is valid when there is no possible way of making the conclusion false and the premises true. One more way of putting it: there is no counterexample that makes the premises true but the conclusion false.</p>
<p>Typically arguments have two or more premises. Modus Ponens, for example, is a style of argument that has a conditional as one statement and a second statement that affirms the antecedent of the conditional. For example: If John lives in Idaho, then he lives in the US. John does indeed live in Idaho. Therefore, John lives in the US.</p>
<p>Not all arguments have to have two or more premises, however. Some arguments can have no premises at all! Tautologies are examples where if you make them the conclusion of an argument with no premises, the argument is still, strictly speaking, valid. (You can’t make the conclusion false! So there’s no counterexample.)</p>
<p>When an argument is valid, we say that the premises <em>entail</em> the conclusion. In many cases we’ll look at arguments with just one premise and one conclusion. So if A is the premise, B the conclusion, and we have a valid argument, then we say that A entails B.</p>
<p>Truth tables can be used to check for entailment. What we do is make sure there is no counterexample. Put differently, we make sure that in every row where the premises are true, the conclusion is also true.</p>
<p>Entailment is an important concept to logicians because it preserves truth. That is, if the premises of an argument are true and you proceed through a sequence of inferences, where each inferential step is a valid one, that there is never a loss of truth. You’ll never go from true premises to a false conclusion in a valid argument.</p>
<p>Something similar is the case if we think of probabilities instead of truth. If A entails B, then the probability of B is at least as high as the probability of A. We have this feature because when A entails B, that means that B has to be true in all the possibilities where A is (if that weren’t the case, we’d have a counterexample). So if B is true in at least all the same places where A is, then the probability of B has to be at least as great as A.</p>
</div>
<div id="inconsistency" class="section level3">
<h3><span class="header-section-number">8.3.3</span> Inconsistency</h3>
<p>A standard light switch is either on or off – it’s not both on and off at the same time. Now imagine that you have two light switches arranged so that when one is on it automatically turns the other one off (and vice versa). In this arrangment, the light switches are never both on at the same time, nor both off at the same time.</p>
<p>Similarily, when we say that two propositions are inconsistent, we mean that whenever one is true the other is false, and when one is false the other is true. Consider ‘<span class="math inline">\(\neg\)</span>(P <span class="math inline">\(\wedge\)</span> Q)’ and ‘P <span class="math inline">\(\wedge\)</span> Q’. When we complete the truth tables for these, we see that they have opposite truth values on each row.</p>
<table>
<thead>
<tr class="header">
<th align="center">P</th>
<th align="center">Q</th>
<th align="center"><span class="math inline">\(\neg\)</span>(P <span class="math inline">\(\wedge\)</span> Q)</th>
<th align="center">P <span class="math inline">\(\wedge\)</span> Q</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">T</td>
<td align="center">T</td>
<td align="center">F<span class="math inline">\(~~~~~~~~~~\)</span></td>
<td align="center">T</td>
</tr>
<tr class="even">
<td align="center">T</td>
<td align="center">F</td>
<td align="center">T<span class="math inline">\(~~~~~~~~~~\)</span></td>
<td align="center">F</td>
</tr>
<tr class="odd">
<td align="center">F</td>
<td align="center">T</td>
<td align="center">T<span class="math inline">\(~~~~~~~~~~\)</span></td>
<td align="center">F</td>
</tr>
<tr class="even">
<td align="center">F</td>
<td align="center">F</td>
<td align="center">T<span class="math inline">\(~~~~~~~~~~\)</span></td>
<td align="center">F</td>
</tr>
</tbody>
</table>
<p>Whenever two propositions are inconsistent, then the probability of the disjunction of those two propositions is the sum of each of them. For example, suppose that A and B are inconsistent. Then <span class="math inline">\(Pr\)</span>(A<span class="math inline">\(\vee\)</span>B) = <span class="math inline">\(Pr\)</span>(A) + <span class="math inline">\(Pr\)</span>(B).</p>
</div>
<div id="logic-probabilities" class="section level3">
<h3><span class="header-section-number">8.3.4</span> Logic Probabilities</h3>
<p>So let’s think again about why the probability of a tautology is 1. This is actually because of two features. First, A and <span class="math inline">\(\neg\)</span>A are inconsistent, so the probability of their disjunction (i.e. <span class="math inline">\(Pr\)</span>(A<span class="math inline">\(\vee\)</span> <span class="math inline">\(\neg\)</span>A) ) is going to be the sum of the probabilty of A and the probablity of <span class="math inline">\(\neg\)</span>A. Second, whatever the probability of A is, the probability of ‘<span class="math inline">\(\neg\)</span>A’ is going to be <span class="math inline">\(1-Pr\)</span>(A). This is because inconsistent propositions cannot have probabilities that vary independently. If the probability of A is fixed, this automatically fixes the probability of ‘<span class="math inline">\(\neg\)</span>A’ (and vice versa). And since ‘<span class="math inline">\(\neg\)</span>A’ will cover all the remaining possibilities that ‘A’ did not cover and the probability of the universe (i.e., all possibilities) is 1, the probability of ‘<span class="math inline">\(\neg\)</span>A’ is <span class="math inline">\(1-Pr\)</span>(A).</p>
<p>What about the case where A and B are not inconsistent? Is the sum of their probabilities somehow connected to the features we have been considering so far? Yes.</p>
<p>Let’s look at the following truth table. Notice that A and B are not inconsistent, since there are rows where their truth values match. In the left most column we have variables representing the probability of each row. If A and B meant ‘lands heads’ and ‘lands tails’ respectively, this exercise would be much easier (since each row has a probability of 0.25). But we’re asking about whether there’s some general pattern that we can express even if we don’t know the probabilities of any row.</p>
<table>
<thead>
<tr class="header">
<th align="center">Probability</th>
<th align="center">A</th>
<th align="center">B</th>
<th align="center">A<span class="math inline">\(\wedge\)</span>B</th>
<th align="center">A<span class="math inline">\(\vee\)</span>B</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(x_1\)</span></td>
<td align="center">T</td>
<td align="center">T</td>
<td align="center">T</td>
<td align="center">T</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(x_2\)</span></td>
<td align="center">T</td>
<td align="center">F</td>
<td align="center">F</td>
<td align="center">T</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(x_3\)</span></td>
<td align="center">F</td>
<td align="center">T</td>
<td align="center">F</td>
<td align="center">T</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(x_4\)</span></td>
<td align="center">F</td>
<td align="center">F</td>
<td align="center">F</td>
<td align="center">F</td>
</tr>
</tbody>
</table>
<p>We already know how to calculate the following probabilities:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(Pr\)</span>(A) = <span class="math inline">\(x_1 + x_2\)</span> since these are the rows where A is true.</li>
<li><span class="math inline">\(Pr\)</span>(B) = <span class="math inline">\(x_1 + x_3\)</span> since these are the rows where B is true.</li>
<li><span class="math inline">\(Pr\)</span>(A<span class="math inline">\(\wedge\)</span>B) = <span class="math inline">\(x_1\)</span> since A<span class="math inline">\(\wedge\)</span>B is true on just the first line</li>
<li><span class="math inline">\(Pr\)</span>(A<span class="math inline">\(\vee\)</span>B) = <span class="math inline">\(x_1 + x_2 + x_3\)</span> since A<span class="math inline">\(\vee\)</span>B is true on lines 1-3.</li>
</ol>
<p>The sum of the probabilities of A and B is then
<span class="math display">\[
Pr(\text{A}) + Pr(\text{B}) = x_1 + x_2 + x_1 + x_3
\]</span></p>
<p>If we add lines 3 and 4, we get
<span class="math display">\[
Pr(\text{A}\wedge\text{B}) + Pr(\text{A}\vee\text{B}) = x_1 + x_1 + x_2 + x_3
\]</span></p>
<p>Notice that the sum of the probabilities is actually the same (after rearranging the order): <span class="math inline">\(x_1 + x_1 + x_2 + x_3\)</span>. And so we have the result that
<span class="math display">\[
Pr(\text{A}) + Pr(\text{B}) = Pr(\text{A}\wedge\text{B}) + Pr(\text{A}\vee\text{B})
\]</span></p>
<p>This is an important result, one that we will use often. Here’s a different way of thinking about it, using an illustration. Let’s ask how to calculate <span class="math inline">\(Pr\)</span>(A<span class="math inline">\(\vee\)</span>B). As a first step, we would just add the probabilities of A and B together, i.e., <span class="math inline">\(Pr\)</span>(A) + <span class="math inline">\(Pr\)</span>(B). However, we don’t know that A and B are inconsistent, so it’s possible that A and B could be true at the same time. So we need to make sure not to double count the intersection. That is, the probability that both A and B are true is already accounted for in <span class="math inline">\(Pr\)</span>(A<span class="math inline">\(\vee\)</span>B), so when we add the probabilities of A and B together, we need to subtract out the probability that both are true at the same time. That what’s going on when we rearrange the result we obtained above to get the following.
<span class="math display">\[
 Pr(\text{A}\vee\text{B}) = Pr(\text{A}) + Pr(\text{B}) - Pr(\text{A}\wedge\text{B}) 
\]</span></p>
</div>
</div>
<div id="exercises-7" class="section level2">
<h2><span class="header-section-number">8.4</span> Exercises</h2>
<div id="proporitions-to-probabilities" class="section level3">
<h3><span class="header-section-number">8.4.1</span> Proporitions to Probabilities</h3>
<p>Consider again our table about the proportion of distilleries that are ownen by multinational companies (these are the first four rows):</p>
<table>
<thead>
<tr class="header">
<th align="center">Input</th>
<th align="right">Output (proportion owned by corps.)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Highlands</td>
<td align="right">0.6</td>
</tr>
<tr class="even">
<td align="center">Speyside</td>
<td align="right">0.4</td>
</tr>
<tr class="odd">
<td align="center">Lowlands</td>
<td align="right">0.3</td>
</tr>
<tr class="even">
<td align="center">Campbeltown</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="center">Islay</td>
<td align="right">0.25</td>
</tr>
<tr class="even">
<td align="center">Islands</td>
<td align="right">0.4</td>
</tr>
</tbody>
</table>
<p>We said that we can’t determine what proportion of mainland distilleries are owned by multinational companies just by looking at the proportions for each region. Explain what information you would need and how you would go about figuring this out.</p>
</div>
<div id="the-conjunction-fallacy" class="section level3">
<h3><span class="header-section-number">8.4.2</span> The Conjunction Fallacy</h3>
<p>Suppose ‘A’ means ‘Linda is a feminist’ and ‘B’ means `Linda is a bank teller’. Consider the truth table for A and B, with corresponding probabilities (Pr) for each assignment of truth values:</p>
<table>
<thead>
<tr class="header">
<th align="center">Pr</th>
<th align="center">A</th>
<th align="center">B</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">0.5</td>
<td align="center">T</td>
<td align="center">T</td>
</tr>
<tr class="even">
<td align="center">0.2</td>
<td align="center">F</td>
<td align="center">T</td>
</tr>
<tr class="odd">
<td align="center">0.25</td>
<td align="center">T</td>
<td align="center">F</td>
</tr>
<tr class="even">
<td align="center">0.05</td>
<td align="center">F</td>
<td align="center">F</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: decimal">
<li><p>Are A and B inconsistent? Why or why not?</p></li>
<li><p>Are A and B equivalent? Why or why not?</p></li>
<li><p>What is <span class="math inline">\(p(A)\)</span>?</p></li>
<li><p>What is <span class="math inline">\(p(B)\)</span>?</p></li>
<li><p>What is <span class="math inline">\(p(A\wedge B)\)</span>?</p></li>
</ol>
</div>
<div id="atomic-vs-conjunctions" class="section level3">
<h3><span class="header-section-number">8.4.3</span> Atomic vs Conjunctions</h3>
<p>Which of the following is true regarding the general relationship between the probability of a single proposition <span class="math inline">\(X\)</span> and the probability of a conjunction that has <span class="math inline">\(X\)</span> as a component?</p>
<div class="line-block">a) <span class="math inline">\(p(X)\geq p(X\wedge Y)\)</span><br />
b) <span class="math inline">\(p(X)\leq p(X\wedge Y)\)</span><br />
   c) <span class="math inline">\(p(X) = p(X\wedge Y)\)</span><br />
   d) None of the above. It depends on the probabilities given to <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</div>
</div>
<div id="disjunction" class="section level3">
<h3><span class="header-section-number">8.4.4</span> Disjunction</h3>
<p>Consider the case of disjunction now. Which of the following is true regarding the general relationship between the probability of a single proposition <span class="math inline">\(X\)</span> and the probability of a disjunction that has <span class="math inline">\(X\)</span> as a component?</p>
<div class="line-block">a) <span class="math inline">\(p(X)\geq p(X\vee Y)\)</span><br />
  b) <span class="math inline">\(p(X)\leq p(X\vee Y)\)</span><br />
  c) <span class="math inline">\(p(X) = p(X\vee Y)\)</span><br />
  d) None of the above. It depends on the probabilities given to <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</div>
</div>
<div id="conjunctions-and-disjunctions" class="section level3">
<h3><span class="header-section-number">8.4.5</span> Conjunctions and Disjunctions</h3>
<p>Let’s compare conjunctions and disjunctions. Which of the following is true regarding the general relationship between the probability of a conjunction and the probability of a disjunction?</p>
<div class="line-block">a) <span class="math inline">\(p(X\wedge Y)\geq p(X\vee Y)\)</span><br />
b) <span class="math inline">\(p(X\wedge Y)\leq p(X\vee Y)\)</span><br />
c) <span class="math inline">\(p(X\wedge Y) = p(X\vee Y)\)</span><br />
d) None of the above. It depends on the probabilities given to <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</div>
</div>
<div id="linda-again" class="section level3">
<h3><span class="header-section-number">8.4.6</span> Linda (again)</h3>
<p>Linda is 31 years old, single, outspoken, and very bright. She majored in philosophy. As a student, she was deeply concerned with issues of discrimination and social justice, and also participated in anti-nuclear demonstrations. Which of the following is most probable?</p>
<ol style="list-style-type: decimal">
<li>Linda is a bank teller</li>
<li>Linda is a bank teller and not a feminist</li>
<li>Linda is a bank teller and a feminist</li>
</ol>

</div>
</div>
</div>
<p style="text-align: center;">
<a href="intervention.html"><button class="btn btn-default">Previous</button></a>
<a href="odds-and-actions.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
